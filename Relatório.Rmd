---
output:
  pdf_document:
    number_sections: yes
    latex_engine: xelatex
fig_caption: yes
margin: auto
fontsize: 11pt
header-includes:
- \usepackage{float}
- \floatplacement{figure}{H}
- \usepackage[brazil, english, portuguese]{babel}
- \usepackage{abstract}
- \usepackage{hyperref}
- \usepackage[style=abnt]{biblatex}
- \addbibresource{ref.bib}
- \usepackage{fontspec}
- \usepackage{geometry}
   \geometry{
   a4paper,
   total={180mm,240mm},
   left=15mm,
   top=20mm,
   }
- \setmainfont{Arial}
link-citations: yes
---


```{r message=FALSE, warning=FALSE, echo=F}
library(knitr)
library(kableExtra)
opts_chunk$set(echo=F)
opts_chunk$set(warning = F)
opts_chunk$set(message= FALSE)
opts_chunk$set(eval=T)
opts_chunk$set(include=T)
opts_chunk$set(fig.align="center")
opts_chunk$set(fig.height = 4)
options(OutDec = ",")
library(plyr)
library(readr)
library(ggplot2)
library(tidyverse)
library(MASS)
library(car)
library(xtable)
library(moments)
library(MVA)
library(mlbench)
library(plotrix)
library(corrplot)
library(ggcorrplot)
library(psych)
library(ca)

```

\renewcommand{\figurename}{Figura}
\renewcommand{\tablename}{Tabela}
\renewcommand{\baselinestretch}{1.5}

\begin{titlepage}
\begin{center} 

\vspace*{1.5cm}

{\LARGE UNICAMP - Universidade Estadual de Campinas}\\[0.2cm] 
{\Large IMECC - Instituto de Matemática, Estatística e Computação Científica}\\[0.2cm] 
{\Large Departamento de Estatística}\\[0.2cm]
{\Large ME731 - Métodos em Análise Multivariada}\\[6.1cm]
{\bf \Large Trabalho Final - ME731}\\[5.5cm] 

\begin{flushright}
{ Caio Henrique de Sousa Lima RA 214144\\
Carlos Eduardo Kamioka RA 168624 \\ 
Giovanni Torres Chaves RA 198105\\
Júlio Mendes Pazelli RA 219494\\
Nathan Blusamarello de Souto RA 222854} \\[5cm] 
\end{flushright}


{Campinas}\\
{2020}
\end{center}
\end{titlepage}

# Questão 1

## Introdução

O banco de dados é composto pelo perfil de tamanho e formato de 48 tartarugas, sendo 24 machos e 24 fêmeas. As informações obtidas foram largura, comprimento e altura. O estudo tinha como objetivo observar e comparar o sexo ao qual o animal pertencia e sua relação com essas medidas físicas. Para realizar a análise desse banco, foi utilizado o software estatístico R e aplicado algumas metodologias como a Análise de Variância Multivariada (MANOVA).

```{r}
turtle = read_table2("q1.txt") %>% arrange(sex)

turtle$length = as.numeric(turtle$length)
turtle$width = as.numeric(turtle$width)
turtle$height = as.numeric(turtle$height)
turtleF = turtle %>% filter(sex == "F") %>% dplyr::select(-sex)
turtleM = turtle %>% filter(sex == "M") %>% dplyr::select(-sex)
```

## Análise descritiva 

```{r}
SumF<- cbind(round(apply(turtleF,2,mean),4),round(apply(turtleF,2,var),4),
                round(apply(turtleF,2,sd),4),
                round(100*apply(turtleF,2,sd)/apply(turtleF,2,mean),4),
                round(apply(turtleF,2,min),4),round(apply(turtleF,2,quantile,0.5),4),
                round(apply(turtleF,2,max),4),
                round(apply(turtleF,2,skewness),4),
                round(apply(turtleF,2,kurtosis),4))
colnames(SumF)<-c("Média","Var.","DP","CV(%)","Min.","Med.","Max.",
                     "CA","Cur.")
```


```{r}
SumM<- cbind(round(apply(turtleM,2,mean),4),round(apply(turtleM,2,var),4),
                round(apply(turtleM,2,sd),4),
                round(100*apply(turtleM,2,sd)/apply(turtleM,2,mean),4),
                round(apply(turtleM,2,min),4),round(apply(turtleM,2,quantile,0.5),4),
                round(apply(turtleM,2,max),4),
                round(apply(turtleM,2,skewness),4),
                round(apply(turtleM,2,kurtosis),4))
colnames(SumM)<-c("Média","Var.","DP","CV(%)","Min.","Med.","Max.",
                     "CA","Cur.")
#xtable(rbind(SumF,SumM))
```

A Tabela \ref{desc} apresenta as medidas resumo das tartarugas, dividas por sexo. Observa-se que as médias das medidas das fêmeas foram maiores que as dos machos, e do mesmo modo as variâncias são bem maiores para o sexo feminino. As assimetrias estão em torno de zero e as curtoses entre 2 e 3, para ambos os sexos.

\begin{table}[H]
\centering
\caption{Medidas resumo}
\label{desc}
\begin{tabular}{lrrrrrrrrr}
  \hline
 & Média & Var. & DP & CV(\%) & Min. & Med. & Max. & CA & Cur. \\ 
  \hline
  \multicolumn{10}{||c||}{Feminino} \\
  \hline
Comprimento & 136,00 & 451,39 & 21,25 & 15,62 & 98,00 & 136,50 & 177,00 & -0,23 & 2,26 \\ 
  Largura & 102,58 & 171,73 & 13,10 & 12,77 & 81,00 & 102,00 & 132,00 & 0,31 & 2,55 \\ 
  Altura & 51,96 & 66,65 & 8,16 & 15,71 & 38,00 & 51,00 & 67,00 & -0,03 & 2,19 \\ 
  \hline
  \multicolumn{10}{||c||}{Masculino} \\
  \hline
  Comprimento & 113,38 & 138,77 & 11,78 & 10,39 & 93,00 & 115,00 & 135,00 & -0,08 & 2,10 \\ 
  Largura & 88,29 & 50,04 & 7,07 & 8,01 & 74,00 & 89,00 & 106,00 & 0,20 & 3,15 \\ 
  Altura & 40,71 & 11,26 & 3,36 & 8,24 & 35,00 & 40,00 & 47,00 & 0,18 & 2,20 \\ 
   \hline
\end{tabular}
\end{table}

A Figura \ref{dispF} mostra que, para ambos os sexos, as medidas de altura, largura e comprimento das tartarugas estão muito correlacionadas e com tendência positiva.

```{r,fig.cap="Matriz de gráfico de dispersões sexo feminino.\\label{dispF}", fig.height=2.5}
library(lattice) 
splom(~turtle[1:3]|sex, data = turtle,  pscales = 0, xlab = "", varname.cex = 0.6,
      varnames = c("Comprimento", "Largura", "Altura"), col = "black")
```

A matriz de covariância para ambos os sexos, vista na Tabela \ref{covF}, parecem ser diferentes, na qual as medidas do sexo masculino aparentam ter variância bem menor se comparado ao sexo feminino. Pode ser visto também na Tabela \ref{Corr} que as matrizes de correlação são aparentemente diferentes, em que as medidas são mais correlacionadas para as fêmeas.

```{r}
#xtable(cov(turtleF))
```

\begin{table}[H]
\centering
\caption{Matriz de Covariâncias (F = Fem, M = Masc).}
\label{covF}
\begin{tabular}{r|rrr|rrr}
  \hline
 & Comprimento (F)& Largura (F) & Altura (F) & Comprimento (M)& Largura (M) & Altura (M) \\ 
  \hline
  length & 451,39 & 271,17 & 168,70 & 138,77 & 79,15 & 37,38\\ 
  width & 271,17 & 171,73 & 103,29 & 79,15 & 50,04 & 21,65\\ 
  height & 168,70 & 103,29 & 66,65 & 37,38 & 21,65 & 11,26\\ 
   \hline
\end{tabular}
\end{table}


```{r}
#xtable(cov(turtleM))
```


```{r}
#xtable(cor(turtleF))
#xtable(cor(turtleM))
```

\begin{table}[ht]
\centering
\caption{Matriz de Correlação (F = Fem, M = Masc).}
\label{Corr}
\begin{tabular}{l|rrr|rrr}
  \hline
 & Comprimento (F)& Largura (F) & Altura (F) & Comprimento (M)& Largura (M) & Altura (M) \\  
  \hline
Comprimento & 1,00 & 0,97 & 0,97 & 1,00 & 0,95 & 0,95 \\  
  Largura & 0,97 & 1,00 & 0,97 & 0,95 & 1,00 & 0,91 \\ 
  Altura & 0,97 & 0,97 & 1,00 & 0,95 & 0,91 & 1,00 \\ 
   \hline
\end{tabular}
\end{table}

Os boxplots da Figura \ref{boxTurtle} mostram que há uma aparente diferença entre os sexos nas três medidas e nota-se que no Comprimento e na Altura dos machos há uma assimetria em torno da mediana, o que pode indicar uma não normalidade. Da mesma forma, os histogramas vistos na Figura \ref{histTurtle} e os gráficos quantil-quantil da Figura \ref{qqTurtle} aparentam seguir uma distribuição diferente da normal, visto que não são simetricas e alguns possuem caudas pesadas. Mesmo com estas observações, iremos continuar com a análise inferencial.

## Análise inferencial

```{r}
Box.teste.Igual.MCov<-function(m.X.completa,v.grupos,v.n,G)
{
  # v.grupos (1,2,3...)
  # m.X.completa : matriz de dados com todos os grupos
  grupo <- 1
  p<- ncol(m.X.completa)
  m.X.k <- m.X.completa[v.grupos==grupo,]
  Sigma.k <- cov(m.X.k)
  m.Sigma.completa <- cbind(grupo,Sigma.k)
  Sigma.P <- (v.n[grupo]-1)*Sigma.k # estimativa ponderada
  aux.k.1 <- (v.n[grupo] - 1)*log(det(Sigma.k))
  grupo <- grupo + 1
  for (i in 2:G)
  {
    m.X.k <- m.X.completa[v.grupos==grupo,] # pegar os dados referentes ao grupo i
    Sigma.k <- cov(m.X.k)
    m.Sigma.completa <- rbind(m.Sigma.completa,cbind(grupo,Sigma.k))
    Sigma.P <- Sigma.P + (v.n[grupo]-1)*Sigma.k # estimativa ponderada
    aux.k.1 <- aux.k.1 + (v.n[grupo] - 1)*log(det(Sigma.k))
    grupo <- grupo + 1
  }
  Sigma.P <- Sigma.P/(sum(v.n)-G)
  
  # Estatística de ajuste
  aux.u <- (sum(1/(v.n - 1)) - (1/(sum(v.n - 1))))*(2*p^2 + 3*p - 1)/(6*(p+1)*(G-1))
  Q.B <-  (1 - aux.u)*(sum(v.n-1)*log(det(Sigma.P)) - aux.k.1)
  aux.v <- 0.5*p*(p+1)*(G-1)
  e.nd.QB <- 1 - pchisq(Q.B,aux.v)
  cat("Estatística do Teste: ", Q.B, "\n")
  cat("nível descritivo: ",e.nd.QB,"\n")
  cat("Matrizes de Covariâncias por grupo: \n")
  print(m.Sigma.completa)
  Sigma.P <-as.matrix(data.frame(Sigma.P))
  list(Sigma.P=Sigma.P)
} # fim da função

# mY: matriz de dados
# fit.model: ajuste da função lm

mSigmareg <- function(mY,fit.model)
{
  mX <- as.matrix(model.matrix(fit.model))
  q <- ncol(mX)
  p<-ncol(mY)
  n <- nrow(mY)
  mB <- matrix(coef(fit.model),q,p)
  mSigma <- t(as.matrix(mY-mX%*%mB))%*%(as.matrix(mY-mX%*%mB))/(n-q)
  return(mSigma)
}

# mY: matriz de dados
# fit.model: ajuste da função lm
# gama: nível de confiança

estim.par.MRNLM <- function(mY,fit.model,gama)

{

vbeta <- c(t(coef(fit.model)))
mSigma<-mSigmareg(mY,fit.model)
mX <-as.matrix(model.matrix(fit.model))
n<-nrow(mX)
q<-ncol(mX)
mSigmabeta <- kronecker(solve(t(mX)%*%mX),mSigma)
epbeta<-sqrt(diag(mSigmabeta))
et <- qt(0.5*(1+gama),df=n-q)
LIIC <- vbeta-et*epbeta
LSIC <- vbeta+et*epbeta
estt <- vbeta/epbeta
pvalor <- 2*(1-pt(abs(estt),df=n-q))
#
mresult <- cbind(vbeta,epbeta,LIIC,LSIC,estt,pvalor)
return(mresult)

  
}

# fit.model: ajuste da função manova
# m.Sigma.P: matriz de variâncias e covariâncias estimada via modelo
# p: número de variáveis
# q: número de parâmetros por variável
# m.C,m.U,m.M: matrizes de interesse

Teste.CBU.M<-function(fit.model,m.Sigma.P,p,q,m.C,m.U,m.M)
{
  m.B <- matrix(coef(fit.model),q,p)
  v.beta <- matrix(t(m.B))
  m.X <- model.matrix(fit.model)
  m.Ca <- kronecker(m.C,t(m.U))
  m.Ma <- matrix(t(m.M))
  v.theta <- m.Ca%*%v.beta - m.Ma
  m.Sigmabeta <- kronecker(solve(t(m.X)%*%m.X),m.Sigma.P)
  estat <- t(v.theta)%*%solve(m.Ca%*%(m.Sigmabeta)%*%t(m.Ca))%*%v.theta
  p.valor <- 1-pchisq(estat,df=nrow(m.C)*ncol(m.U))
  cat("Estatistica Qui-quadrado = ",round(estat,2),"\n")
  cat("pvalor = ",round(p.valor,4),"\n")
  cat("Matriz C :","\n")
  print(m.C)
  cat("Matriz U :","\n")
  print(m.U)
  cat("Matriz M :","\n")
  print(m.M)
}

# mY: matriz de dados
# mresult: resultado da função manova
# var: escolha da variável (1,2,..)
# typeresid:
  # univariate (RS-veja slides)
  # multivariate (RSM-veja slides)
# wplot:
  # diagnostics: quatro gráficos
  # envelope: gráfico de envelope
  
gen.graf.resid<-function(mY,mresult,var,typeresid,wplot){
mresiduo <- mresult$residuals
mbeta <- coef(mresult) 
mX <- as.matrix(model.matrix(mresult))
n <- nrow(mX)
p <- ncol(mbeta)
q <- nrow(mbeta)
mSigma<-t(mY-mX%*%mbeta)%*%(mY-mX%*%mbeta)/(n-q)
if (typeresid == "univariate")
{
auxres <- diag((diag(n) - mX%*%solve(t(mX)%*%mX)%*%t(mX)))
mresiduo <- mresiduo/(sqrt((matrix(auxres,n,p))%*%diag(diag(mSigma))))
}
else if (typeresid == "multivariate")
{
mresiduo <- t(solve(t(chol(mSigma)))%*%t(mresiduo))
}
mfit <- fitted.values(mresult)
#
if (wplot == "diagnostics")
{
par(mfrow =c(2,2))
plot(mresiduo[,var],ylim=c(min(-3,min(mresiduo[,var])),max(3,max(mresiduo[,var]))),xlab="índice",ylab="resíduo studentizado")
abline(-2,0,lty=2)
abline(2,0,lty=2)
abline(0,0,lty=2)
#
plot(mfit[,var],mresiduo[,var],ylim=c(min(-3,min(mresiduo[,var])),max(3,max(mresiduo[,var]))),xlab="valor ajustado",ylab="resíduo studentizado")
abline(-2,0,lty=2)
abline(2,0,lty=2)
abline(0,0,lty=2)
#
hist(mresiduo[,var],probability=TRUE,xlab="resíduo studentizado",main="",ylab="densidade")
#
qqPlot((mresiduo[,var]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab=paste("quantil do resíduo studentizado"),cex=1.2)
}

else if (wplot == "envelope")
{
par(mfrow =c(1,1))
qqPlot((mresiduo[,var]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab=paste("quantil do resíduo studentizado"),cex=1.2)
}
}

```

```{r}
sex = turtle$sex
turtled = turtle %>% dplyr::select(-sex)
v.grupos = as.vector(cbind(as.numeric(factor(sex))))
v.n = c(24,24)
G = 2
```

```{r,warning = FALSE}
#m.Sigma.P<-Box.teste.Igual.MCov(turtled,v.grupos,v.n,G)$Sigma.P
#xtable(m.Sigma.P)
fit.model<-m.ajuste <- manova(as.matrix(turtled) ~ sex)
#summary.manova(m.ajuste,test="Wilks")
#summary.manova(m.ajuste,test="Pillai")
#summary.manova(m.ajuste,test="Hotelling-Lawley")
#summary.manova(m.ajuste,test="Roy")
```

Como visto na Análise Descritiva, as matrizes de covariâncias aparentaram serem diferentes entre os sexos, e assim, para observar inferencialmente essa diferença foi realizado um teste de Box. Obteve-se uma estatística de 24,04 e um p-valor de 0.0005, logo temos que as matrizes realmente são diferentes. Após isso, foi realizado uma MANOVA com o objetivo de visualizar se existe diferença entre os vetores de médias para ambos os sexos, e como visto na Tabela \ref{MANOVA1}, rejeitamos a hipótese dos vetores serem iguais. 

\begin{table}[H]
\centering
\caption{Resultados da MANOVA}
\label{MANOVA1}
\begin{tabular}{rrrr}
  \hline
 & Valor & Aproximação pela distribuição F & p-valor \\ 
  \hline
Wilks & 0,41 & 21,28 & $<$ 0,0001 \\ 
Pillai & 0,59 & 21,28 & $<$ 0,0001 \\ 
Hotelling-Lawley & 1,45 & 21,28  & $<$ 0,0001 \\ 
Roy & 1,45 & 21,28 & $<$ 0,0001  \\ 
   \hline
\end{tabular}
\end{table}

Foi estimado então os parâmetros do modelo, como visto na Tabela \ref{MRNLM}, e vemos que todos foram significativos. Dessa forma, é interessante verificar quais medidas se diferem entre os sexos, e portanto aplicamos um teste CBU. O teste CBU, Tabela \ref{CBUtestes}, mostra que todas as medidas são estatísticasmente diferentes entre os sexos.


```{r}
aux<-summary.aov(m.ajuste)
fit.modelLM <- lm(as.matrix(turtled) ~ sex)
#summary(fit.modelLM)


# Estimativa dos parâmetros
#xtable(estim.par.MRNLM(turtled,fit.modelLM,0.95)[,c(1,2,5,6)])
#estim.par.MRNLM(turtled,fit.modelLM,0.95)[,c(1,2,5,6)]
```

\begin{table}[H]
\centering
\caption{Estimativas dos parâmetros do modelo}
\label{MRNLM}
\begin{tabular}{rrrrr}

  \hline
 & Estimativa & EP & Estatística t & p-valor \\ 
  \hline
$\mu_1$ & 136,00 & 3,51 & 38,79 & $<$ 0,0001 \\ 
  $\mu_2$ & 102,58 & 2,15 & 47,72 & $<$ 0,0001 \\ 
  $\mu_3$ & 51,96 & 1,27 & 40,78 & $<$ 0,0001 \\ 
 $\alpha_{21}$ & -22,63 & 4,96 & -4,56 & $<$ 0,0001 \\ 
  $\alpha_{22}$ & -14,29 & 3,04 & -4,70 & $<$ 0,0001 \\ 
  $\alpha_{23}$ & -11,25 & 1,80 & -6,24 & $<$ 0,0001 \\ 
   \hline
\end{tabular}
\end{table}



```{r}
m.C1 <- cbind(0,1) #  F X M
m.M = 0
p = 3
```


\begin{table}[H]
\centering
\caption{Testes CBU ($\alpha_{2i} = 0$)}
\label{CBUtestes}
\begin{tabular}{rrr}

  \hline
 Parâmetro &  Estatística Qui-quadrado & p-valor \\ 
  \hline
 $\alpha_{21}$ (Length)  & 20,82 & $<$ 0,0001 \\ 
  $\alpha_{22}$ (Width) & 22,10 & $<$ 0,0001 \\
  $\alpha_{23}$ (Height) & 38,99 & $<$ 0,0001 \\
   \hline
\end{tabular}
\end{table}


```{r}
m.U <- rbind(1,0,0)
#Teste.CBU.M(fit.model,m.Sigma.P,p,G,m.C1,m.U,m.M)
```

```{r}
m.U <- rbind(0,1,0)
#Teste.CBU.M(fit.model,m.Sigma.P,p,G,m.C1,m.U,m.M)
```

```{r}
m.U <- rbind(0,0,1)
#Teste.CBU.M(fit.model,m.Sigma.P,p,G,m.C1,m.U,m.M)
```


Avaliando os resíduos do modelo ajustado nas Figuras \ref{rs1}, \ref{rs2} e \ref{rs3}, referentes ao Comprimento, Largura e Altura, respectivamente, podemos observar que a suposição de homocedasticidade e de normalidade não parecem ser razoáveis.


```{r,fig.cap="Análise de Resíduos - Comprimento \\label{rs1}"}
gen.graf.resid(turtled %>% as.matrix(), fit.model, 1, "univariate", "diagnostics") %>% invisible()
```

```{r,fig.cap="Análise de Resíduos - Largura \\label{rs2}"}
gen.graf.resid(turtled %>% as.matrix(), fit.model, 2, "univariate", "diagnostics") %>% invisible()
```

```{r,fig.cap="Análise de Resíduos - Altura \\label{rs3}"}
gen.graf.resid(turtled %>% as.matrix(), fit.model, 3, "univariate", "diagnostics") %>% invisible()
```


## Conclusão

\subsection*{Referências}

\textit{Azevedo, C. L. N. (2020). Notas de aula sobre análise multivariada de
dados} <https://www.ime.unicamp.br/~cnaber/Material_AM_2S_2020.htm>.

\subsection*{Apendice}



```{r,fig.cap="Boxplots das variáveis por sexo.\\label{boxTurtle}"}
par(mfrow=c(2,3))
boxplot(turtleF[,1],cex=1.2,cex.lab=1.2,main="Comprimento (F)")
boxplot(turtleF[,2],cex=1.2,cex.lab=1.2,main="Largura (F)")
boxplot(turtleF[,3],cex=1.2,cex.lab=1.2,main="Altura (F)")
boxplot(turtleM[,1],cex=1.2,cex.lab=1.2,main="Comprimento (M)")
boxplot(turtleM[,2],cex=1.2,cex.lab=1.2,main="Largura (M)")
boxplot(turtleM[,3],cex=1.2,cex.lab=1.2,main="Altura (M)")
```


```{r,fig.cap="Histogramas das variáveis por sexo.\\label{histTurtle}"}
par(mfrow=c(2,3))
hist(turtleF$length,probability=TRUE,main="Comprimento (F)",xlab="",ylab="")
hist(turtleF$width,probability=TRUE,main="Largura (F)",xlab="",ylab="")
hist(turtleF$height,probability=TRUE,main="Altura (F)",xlab="",ylab="")
hist(turtleM$length,probability=TRUE,main="Comprimento (M)",xlab="",ylab="")
hist(turtleM$width,probability=TRUE,main="Largura (M)",xlab="",ylab="")
hist(turtleM$height,probability=TRUE,main="Altura (M)",xlab="",ylab="")
```


```{r,fig.cap="QQplots das variáveis por sexo.\\label{qqTurtle}"}
par(mfrow=c(2,3))
qqPlot(scale(turtleF$length),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Comprimento (F)",cex=1.2) %>% invisible()
qqPlot(scale(turtleF$width),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Largura (F)",cex=1.2)%>% invisible()
qqPlot(scale(turtleF$height),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Altura (F)",cex=1.2)%>% invisible()
qqPlot(scale(turtleM$length),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Comprimento (M)",cex=1.2)%>% invisible()
qqPlot(scale(turtleM$width),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Largura (M)",cex=1.2)%>% invisible()
qqPlot(scale(turtleM$height),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Altura (M)",cex=1.2)%>% invisible()
```

\newpage

# Questão 2:

## Introdução

O banco de dados é composto pelos resultados de 25 atletas em provas que compõem o heptatlo, nas olímpiadas de 1988, em Seul. São 7 resultados de cada prova do heptatlo e o escore total na competição. O estudo tem como objetivo utilizar a metodologia das componentes principais para caracterizar as atletas, com relação as variáveis medidas. Para realizar a análise desse banco, foi utilizado o software estatístico R.

```{r}
hep = heptathlon[,1:7]
nvar <- 8
```

## Análise descritiva

Antes de iniciar nossa análise, foi retirado a variável escore total. O motivo da remoção, foi devido ao fato de que a variável é, de certa forma, uma combinação linear das outras variáveis. Podendo trazer viés para o futuro rank gerado.

A Tabela \ref{med_res2} contem as medidas resumo dos resultados das provas. Podemos notar que a maioria das variáveis não tem uma curtose ideal (próxima de 3) e que os coeficientes de assimetria também não foram ideais. Também é possível notar que para as provas shot, javelin e run800m, os resultados das atletas foram mais dispersos comparado com as outras variáveis.

```{r}
SumHep<- cbind(round(apply(hep,2,mean),4),round(apply(hep,2,var),4),
                round(apply(hep,2,sd),4),
                round(100*apply(hep,2,sd)/apply(hep,2,mean),4),
                round(apply(hep,2,min),4),round(apply(hep,2,quantile,0.5),4),
                round(apply(hep,2,max),4),
                round(apply(hep,2,skewness),4),
                round(apply(hep,2,kurtosis),4))
colnames(SumHep)<-c("Média","Var.","DP","CV(%)","Min.","Med.","Max.",
                     "CA","Cur.")
#xtable(SumHep)
```

\begin{table}[H]
\centering
\caption{Medidas resumo dos resultados das provas}
\label{med_res2}
\begin{tabular}{rrrrrrrrrr}
  \hline
 & Média & Var. & DP & CV(\%) & Min. & Med. & Max. & CA & Cur. \\ 
  \hline
hurdles & 13,84 & 0,54 & 0,74 & 5,32 & 12,69 & 13,75 & 16,42 & 1,65 & 7,22 \\ 
  highjump & 1,78 & 0,01 & 0,08 & 4,37 & 1,50 & 1,80 & 1,86 & -1,99 & 7,87 \\ 
  shot & 13,12 & 2,23 & 1,49 & 11,37 & 10,00 & 12,88 & 16,23 & 0,18 & 2,78 \\ 
  run200m & 24,65 & 0,94 & 0,97 & 3,93 & 22,56 & 24,83 & 26,61 & -0,17 & 2,62 \\ 
  longjump & 6,15 & 0,22 & 0,47 & 7,71 & 4,88 & 6,25 & 7,27 & -0,48 & 4,28 \\ 
  javelin & 41,48 & 12,57 & 3,55 & 8,55 & 35,68 & 40,28 & 47,50 & 0,16 & 1,89 \\ 
  run800m & 136,05 & 68,74 & 8,29 & 6,09 & 124,20 & 134,74 & 163,43 & 1,40 & 5,89 \\ 
   \hline
\end{tabular}
\end{table}

A Figura \ref{disp2} contém a matriz de gráfico de dispersões dos resultados de cada prova. Podemos notar correlações positivas e correlações negativas entre as variáveis. A Tabela \ref{corr2} contem a matriz de correlação dos resultados de cada prova. Podemos notar que as provas de corrida são negativamente correlacionadas com as provas de desempenho medidas em metros. A mesma coisa acontece comparando a covariância entre as provas de desempenho medidas em metros com as provas de corrida.

```{r,fig.cap="Matriz de gráfico de dispersões entre as variáveis.\\label{disp2}"}
plot(hep,cex=1.5,cex.lab=1.5,pch=1)
```

```{r}
#xtable(cor(hep))
#cor(hep)
```

\begin{table}[H]
\centering
\caption{Matriz de correlações}
\label{corr2}
\begin{tabular}{rrrrrrrr}
  \hline
 & hurdles & highjump & shot & run200m & longjump & javelin & run800m \\ 
  \hline
hurdles & 1,00 & -0,81 & -0,65 & 0,77 & -0,91 & -0,01 & 0,78 \\ 
  highjump & -0,81 & 1,00 & 0,44 & -0,49 & 0,78 & 0,00 & -0,59 \\ 
  shot & -0,65 & 0,44 & 1,00 & -0,68 & 0,74 & 0,27 & -0,42 \\ 
  run200m & 0,77 & -0,49 & -0,68 & 1,00 & -0,82 & -0,33 & 0,62 \\ 
  longjump & -0,91 & 0,78 & 0,74 & -0,82 & 1,00 & 0,07 & -0,70 \\ 
  javelin & -0,01 & 0,00 & 0,27 & -0,33 & 0,07 & 1,00 & 0,02 \\ 
  run800m & 0,78 & -0,59 & -0,42 & 0,62 & -0,70 & 0,02 & 1,00 \\ 
   \hline
\end{tabular}
\end{table}

As Figuras \ref{box2}, \ref{hist2} e \ref{qq2} contém os boxplots, os histogramas e os QQplots dos resultados de cada prova, respectivamente. Podemos perceber, pelas figuras, a existência de pelo menos uma variável que não segue uma distribuição normal. Sendo assim, rejeita-se a normalidade multivariada. Já a Figura \ref{correlo2} contém o correlograma dos resultados de cada prova. Nele, reforça-se a ideia de que as provas de corrida pertencem a um grupo e as provas de desempenho medidas em distância a outro. Ou seja, a correlações entre provas de grupos distintos são negativas e, correlações do mesmo grupo, positivas.

```{r,fig.cap="Boxplots das variáveis.\\label{box2}"}
par(mfrow=c(2,4))
boxplot(hep[,1],cex=1.2,cex.lab=1.2,main="hurdles")
boxplot(hep[,2],cex=1.2,cex.lab=1.2,main="highjump")
boxplot(hep[,3],cex=1.2,cex.lab=1.2,main="shot")
boxplot(hep[,4],cex=1.2,cex.lab=1.2,main="run200m")
boxplot(hep[,5],cex=1.2,cex.lab=1.2,main="longjump")
boxplot(hep[,6],cex=1.2,cex.lab=1.2,main="javelin")
boxplot(hep[,7],cex=1.2,cex.lab=1.2,main="run800m")
#boxplot(hep[,8],cex=1.2,cex.lab=1.2,main="Pontuação total")
```


```{r,fig.cap="Histogramas das variáveis.\\label{hist2}"}
par(mfrow=c(2,4))
hist(hep[,1],probability=TRUE,main="hurdles",xlab="",ylab="")
hist(hep[,2],probability=TRUE,main="highjump",xlab="",ylab="")
hist(hep[,3],probability=TRUE,main="shot",xlab="",ylab="")
hist(hep[,4],probability=TRUE,main="run200m",xlab="",ylab="")
hist(hep[,5],probability=TRUE,main="longjump",xlab="",ylab="")
hist(hep[,6],probability=TRUE,main="javelin",xlab="",ylab="")
hist(hep[,7],probability=TRUE,main="run800m",xlab="",ylab="")
#hist(hep[,8],probability=TRUE,main="Pontuação total",xlab="",ylab="")
```

```{r,fig.cap="QQplots das variáveis.\\label{qq2}"}
par(mfrow=c(2,4))
qqPlot(scale(hep[,1]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="hurdles",cex=1.2) %>% invisible()
qqPlot(scale(hep[,2]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="highjump",cex=1.2) %>% invisible()
qqPlot(scale(hep[,3]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="shot",cex=1.2) %>% invisible()
qqPlot(scale(hep[,4]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="run200m",cex=1.2) %>% invisible()
qqPlot(scale(hep[,5]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="longjump",cex=1.2) %>% invisible()
qqPlot(scale(hep[,6]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="javelin",cex=1.2) %>% invisible()
qqPlot(scale(hep[,7]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="run800m",cex=1.2) %>% invisible()
#qqPlot(scale(hep[,8]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Pontuação total",cex=1.2)
```


```{r,fig.cap="Correlograma das variáveis.\\label{correlo2}"}
corrplot(cor(hep), order = "hclust", tl.col='black', tl.cex=.75) 
```

## Análise inferencial

O objetivo principal da análise é classificar os atletas, com relação as variáveis medidas, bem como reduzir a dimensão dos dados, para futuras análises, veja mais ...

Podemos ver pela Figura \ref{scree} e Tabela \ref{var_exp} que duas componentes principais explicam, aproximadamente, 80\% da variabilidade dos dados. Com isso, como podemos ver na Tabela \ref{comp2}, foram retidas apenas duas componentes. Nessa tabela, também é possível ver que para criar o rank, a componente principal mais indicada é a primeira, pois é um contraste entre os resultados das provas de tempo e distância, o que reforça as correlações encontradas anteriormente. Os pesos das provas de corrida são positivos, já os pesos das provas de desempenho medidas em distância são negativos. Como estamos utilizando a matriz de correlações, os resultados do desempenho de cada atleta estão padronizados. Ou seja, para variáveis de tempo, atletas com valores negativos (tempo abaixo da média) possuem um desempenho melhor. Para as variáveis de distância, atletas com valores negativos (distância abaixo da média) possuem um desempenho pior. Com isso, os atletas que se destacaram no heptatlo teriam um escore menor. Portanto, para melhor interpretabilidade do escore, o mesmo foi multiplicado por -1, pois, desta forma, atletas com escore mais alto tiveram um desempenho melhor.

Os resultados estão na Tabela \ref{rank}. Podemos ver que o rank para algumas atletas foi alterado com a análise de componentes principais.

```{r}
p=7
m.cor<-cor(hep)
aut.val <-  eigen(m.cor)$values
aut.vec <- -(eigen(m.cor)$vectors)
m.aut.val <- t(matrix(((aut.val)),p,p))
result.cp.cor <- princomp(hep,cor=TRUE)

pca_importance <- function(x) {
  vars <- x$sdev^2
  vars <- vars/sum(vars)
  rbind(`PVE (%)` = vars*100, 
        `PVEA (%)` = cumsum(vars)*100)
}

#pca_importance(result.cp.cor)
#pca_importance(result.cp.cor) %>% xtable()

#corr.cp.var <- aut.vec*sqrt(m.aut.val)
#summary(result.cp.cor)$importance
```


```{r,fig.cap="Screeplot das variáveis.\\label{scree}"}
screeplot(result.cp.cor,type=c("lines"),main="",cex=1.2,cex.lab=1.2,cex.main=1.2)

#result.cp.cor$loadings[1:7,1:2]
#xtable(result.cp.cor$loadings[1:7,1:2] %>% as.data.frame())

cp1 = result.cp.cor$loadings[,1]
```

\begin{table}[H]
\centering
\caption{Variância Explicada}
\label{var_exp}
\begin{tabular}{rp{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}p{1cm}}
  \hline
 & Comp.1 & Comp.2 & Comp.3 & Comp.4 & Comp.5 & Comp.6 & Comp.7 \\ 
  \hline
PVE (\%) & 63,72 & 17,06 & 7,44 & 6,53 & 3,50 & 1,04 & 0,70 \\ 
  PVEA (\%) & 63,72 & 80,78 & 88,22 & 94,75 & 98,26 & 99,30 & 100,00 \\  
   \hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Componentes principais}
\label{comp2}
\begin{tabular}{rrr}
  \hline
 & Comp.1 & Comp.2 \\ 
  \hline
hurdles & 0,45 & 0,16 \\ 
  highjump & -0,38 & -0,25 \\ 
  shot & -0,36 & 0,29 \\ 
  run200m & 0,41 & -0,26 \\ 
  longjump & -0,46 & -0,06 \\ 
  javelin & -0,08 & 0,84 \\ 
  run800m & 0,37 & 0,22 \\ 
   \hline
\end{tabular}
\end{table}

```{r}
hep = scale(heptathlon[,1:7])
score_comp =result.cp.cor$loadings[1:7,1]
nominhos = row.names(hep)
escore = as.matrix(addmargins(cbind(hep[,1]*score_comp[1],hep[,2]*score_comp[2],hep[,3]*score_comp[3],hep[,4]*score_comp[4],hep[,5]*score_comp[5],hep[,6]*score_comp[6],hep[,7]*score_comp[7])))[1:25,8]
rankreal = c(seq(1,25,1))
hep_score = as.tibble(cbind(hep,rankreal,escore))
h_new_score = hep_score %>% arrange(escore)
ranknovo = c(seq(1,25,1))
h_new_score = cbind(h_new_score,ranknovo)[,8:10] 
h_new_score = h_new_score %>% mutate(escore = -escore)
row.names(h_new_score)<- nominhos
colnames(h_new_score)<-c("Classificação original","Escore","Novo rank")

#xtable(h_new_score[14:25,])
```


\begin{table}[H]
\centering
\caption{Rankings e escores dos atletas}
\label{rank}
\begin{tabular}{r|r p{1cm} p{1cm}|r|r p{1cm} p{1cm}}
  \hline
 Atleta & Rank & Escore PCA & Novo rank & Atleta & Rank & Escore PCA & Novo rank\\ 
  \hline
Joyner-Kersee (USA) & 1 & 4,12 & 1 & Braun (FRG) & 14 & -0,00 & 14 \\  
  John (GDR) & 2 & 2,88 & 2 & Ruotsalainen (FIN) & 13 & -0,02 & 15 \\ 
  Behmer (GDR) & 3 & 2,65 & 3 & Yuping (CHN) & 15 & -0,09 & 16 \\ 
  Sablovskaite (URS) & 5 & 1,36 & 4 & Hagger (GB) & 17 & -0,17 & 17 \\ 
  Choubenkova (URS) & 4 & 1,34 & 5 & Brown (USA) & 18 & -0,52 & 18 \\ 
  Schulz (GDR) & 12 & 1,19 & 6 & Mulliner (GB) & 20 & -1,09 & 19 \\  
  Fleming (AUS) & 7 & 1,10 & 7 & Hautenauve (BEL) & 19 & -1,13 & 20 \\ 
  Greiner (USA) & 6 & 1,04 & 8 & Kytola (FIN) & 21 & -1,45 & 21 \\  
  Lajbnerova (CZE) & 8 & 0,92 & 9 & Geremias (BRA) & 22 & -2,01 & 22 \\  
  Bouraga (URS) & 10 & 0,76 & 10 & Hui-Ing (TAI) & 23 & -2,88 & 23 \\  
  Wijnsma (HOL) & 11 & 0,56 & 11 & Jeong-Mi (KOR) & 24 & -2,97 & 24 \\  
  Dimitrova (BUL) & 9 & 0,53 & 12 & Launa (PNG) & 25 & -6,27 & 25 \\  
  Scheider (SWI) & 16 & 0,14 & 13 \\ 
   \hline
\end{tabular}
\end{table}

## Apêndice

```{r}
#xtable(cov(hep))
#cov(hep)
```

\begin{table}[H]
\centering
\caption{Matriz de covariâncias}
\label{cov2}
\begin{tabular}{rrrrrrrr}
  \hline
 & hurdles & highjump & shot & run200m & longjump & javelin & run800m \\ 
  \hline
hurdles & 0,54 & -0,05 & -0,72 & 0,55 & -0,32 & -0,02 & 4,76 \\ 
  highjump & -0,05 & 0,01 & 0,05 & -0,04 & 0,03 & 0,00 & -0,38 \\ 
  shot & -0,72 & 0,05 & 2,23 & -0,99 & 0,53 & 1,42 & -5,19 \\ 
  run200m & 0,55 & -0,04 & -0,99 & 0,94 & -0,38 & -1,14 & 4,96 \\ 
  longjump & -0,32 & 0,03 & 0,53 & -0,38 & 0,22 & 0,11 & -2,75 \\ 
  javelin & -0,02 & 0,00 & 1,42 & -1,14 & 0,11 & 12,57 & 0,59 \\ 
  run800m & 4,76 & -0,38 & -5,19 & 4,96 & -2,75 & 0,59 & 68,74 \\
   \hline
\end{tabular}
\end{table}

\newpage


# Questão 3

## Introdução

Os dados foram retirados de um estudo feita para comparar a relação entre status socioeconômico dos pais com a saúde mental dos estudados. As classificações de status foram de A (alto) até E (baixo) e para saúde foram boa, presença fraca de sintomas, presença moderada de sintomas e debilitado. O número de indivíduos testados foi de 1760 indivíduos, distribuídos da seguinte forma:

\begin{table}[H]
\centering
\caption{Saúde Mental x Status Socioeconômico dos pais}
\label{TabCont}
\begin{tabular}{|l|ccccc|c|}
  \hline
  & \multicolumn{5}{c|}{\bf{Status Socioeconômico dos pais}} & \\
  \hline
 \bf{Saúde Mental} & \bf{A} & \bf{B} & \bf{C} & \bf{D} & \bf{E} & \bf{Total} \\ 
  \hline
Boa & 121,00 & 57,00 & 72,00 & 36,00 & 21,00 & 307,00 \\ 
  Presença fraca de sintomas & 188,00 & 105,00 & 141,00 & 97,00 & 71,00 & 602,00 \\ 
  Presença moderada de sintomas & 112,00 & 65,00 & 77,00 & 54,00 & 54,00 & 362,00 \\ 
  Debilitado & 186,00 & 60,00 & 94,00 & 78,00 & 71,00 & 489,00 \\ 
  \hline
Total & 607,00 & 287,00 & 384,00 & 265,00 & 217,00 & 1760,00 \\ 
   \hline
\end{tabular}
\end{table}


## LETRA A

O modelo probabilístico gerador da tabela de contigência é uma multinomial de tamanho 1760 e 20 categorias. Considerando $p_{ij}$ a probabilidade de pertencer as categorias $i$ de Saúde Mental e $j$ de Status socioeconômico dos pais, em que $p_{i.} = \sum_{j = 1}^Jp_{ij}$ e $p_{.j} = \sum_{i = 1}^Ip_{ij}$ são as probabilidades marginais de cada unidade amostral pertencer, respectivamente, à categoria $i$ de Saúde Mental e à categoria $j$ de Status socioeconômico dos pais. Há então o interesse de testar a seguinte hipótese:

\begin{equation}
\label{modeloanovaRCBD}
\left\{\begin{array}{l}
H_0: p_{ij} = p_{i.}p_{.j}, \forall \space i,j  \\
H_1: p_{ij} \neq p_{i.}p_{.j}, \textit{para pelo menos um par (i,j)} 
\end{array}\right.
\end{equation}

Ou seja, $H_0$: as variáveis são estatísticamente independentes e $H_1$: caso contrário. Deste modo, sob $H_0$, temos a estatística do teste $Q = \sum_{i=1}^I\sum_{j=1}^J\frac{(X_{ij} - E_{ij})^2}{E_{ij}}$, em que $E_{ij} = \frac{X_{i.}X_{.j}}{X_{..}}$. Sob a suposição de idependência e com tamanho amostral suficiente grande, temos que $Q \approx \chi^2_{(I-1)(J-1)}$.



```{r}
`Saúde mental`<- array(c(121,188,112,186,
                57,105,65,60,
                72,141,77,94,
                36,97,54,78,
                21,71,54,71),
 dim = c(4, 5), dimnames = list(`Saúde mental` = c("Boa","Presença fraca de sintomas","Presença moderada de sintomas","Debilitado"),
 ` Status socioeconômico dos pais` = c("A","B","C","D","E")))
#xtable(addmargins(`Saúde mental`))
#addmargins(`Saúde mental`)
teste3 <- chisq.test(`Saúde mental`)
```


Levando em conta um nível de significância de 5%, obteve-se uma estatística do teste $Q = 31,17$ e um p-valor = 0,0002, e rejeitamos então a hipótese de independência entre Saúde Mental e Status Socioeconômico dos pais.

## LETRA B


```{r}
margins = addmargins(`Saúde mental`)
#xtable(margins/1760*100)
```

Observando a Tabela \ref{PerfLin}, com o perfil de linhas, vemos que em relação as pessoas com saúde mental boa, 39,41%, 18,57% e 23,45% são por terem pais com condições socioeconômicas mais altas A, B e C, respectivamente, que são maiores do que as respectivas proporções na população geral. Do mesmo modo, pessoas com presença fraca de sintomas se destacam em status medianos (B, C e D), pessoas com sintomas moderados nos status B e E, e por fim, pessoas debilitadas são maioria no maior status (A) e nos menores (D e E).


```{r}
n = sum(`Saúde mental`)
linhas = `Saúde mental`
lin = dim(linhas)[1]
for (i in 1:lin){linhas[i,] = linhas[i,]/sum(linhas[i,])*100}
`Total` = c(sum(`Saúde mental`[,1]),sum(`Saúde mental`[,2]),sum(`Saúde mental`[,3]),sum(`Saúde mental`[,4]),sum(`Saúde mental`[,5]))/n*100
#xtable(addmargins(rbind(linhas,`Total`))[1:5,1:6])
#xtable(addmargins(rbind(linhas,`Total`))[1:5,1:6])
```
\begin{table}[H]
\centering
\caption{Perfil de Linhas ($\times$100).}
\label{PerfLin}
\begin{tabular}{|l|ccccc|c|}
  \hline
  & \multicolumn{5}{c|}{\space \bf{Status Socioeconômico dos pais}} &\\
  \hline
 \bf{Saúde Mental} & \bf{A} & \bf{B} & \bf{C} & \bf{D} & \bf{E} & \bf{Total} \\ 
  \hline
  Boa & \bf{39,41} & \bf{18,57} & \bf{23,45} & 11,73 & 6,84 & 100,00 \\ 
  Presença fraca de sintomas & 31,23 & \bf{17,44} & \bf{23,42} & \bf{16,11} & 11,79 & 100,00 \\ 
  Presença moderada de sintomas & 30,94 & \bf{17,96} & 21,27 & 14,92 & \bf{14,92} & 100,00 \\ 
  Debilitado & \bf{38,04} & 12,27 & 19,22 & \bf{15,95} & \bf{14,52} & 100,00 \\ 
  Total & 34,49 & 16,31 & 21,82 & 15,06 & 12,33 & 100,00 \\ 
   \hline
\end{tabular}
\end{table}

Analisando o perfil de colunas na Tabela \ref{PerfCol}, vemos que a maioria das pessoas com pais nos status A possuem saúde mental boa ou debilitada, em relação ao status B com saude mental boa, sintomas fracos ou sintomas moderados, o status C com saúde mental boa ou sinomas fracos, o status D com sintomas fracos ou debilitado, e por fim, no status E a maioria tem sintomas moderados ou estão debilitadas.

```{r}
n = sum(`Saúde mental`)
colunas = `Saúde mental`
col = dim(linhas)[2]
for (i in 1:col){colunas[,i] = colunas[,i]/sum(colunas[,i])*100}
`Total` = c(sum(`Saúde mental`[1,]),sum(`Saúde mental`[2,]),sum(`Saúde mental`[3,]),sum(`Saúde mental`[4,]))/n*100
#xtable(addmargins(rbind(colunas,`Total`))[1:5,1:6])
#xtable(addmargins(cbind(colunas,`Total`))[1:5,1:6])
```
\begin{table}[H]
\centering
\caption{Perfil de Colunas ($\times$100).}
\label{PerfCol}
\begin{tabular}{|l|ccccc|c|}
  \hline
  & \multicolumn{5}{c|}{\bf{Status Socioeconômico dos pais}} & \\
  \hline
 \bf{Saúde Mental} & \bf{A} & \bf{B} & \bf{C} & \bf{D} & \bf{E} & \bf{Total} \\ 
  \hline
Boa & \bf{19,93} & \bf{19,86} & \bf{18,75} & 13,58 & 9,68 & 17,44 \\ 
  Presença fraca de sintomas & 30,97 & \bf{36,59} & \bf{36,72} & \bf{36,60} & 32,72 & 34,20 \\ 
  Presença moderada de sintomas & 18,45 & \bf{22,65} & 20,05 & 20,38 & \bf{24,88} & 20,57 \\ 
  Debilitado & \bf{30,64} & 20,91 & 24,48 & \bf{29,43} & \bf{32,72} & 27,78 \\ 
  Total & 100,00 & 100,00 & 100,00 & 100,00 & 100,00 & 100,00 \\ 
   \hline
\end{tabular}
\end{table}


## LETRA C

```{r}
resultCA <- ca(`Saúde mental`) # names(resultCA)
inercia<-summary(resultCA)$scree # names(summary(resultCA))
#xtable(cbind(sqrt(inercia[,2]), inercia[,2],inercia[,3],inercia[,4]),digits=4)
```

A Tabela \ref{inercia} apresenta a incércia e a proporção de variabilidade explicada das duas primeiras componentes. Vemos que o percentual de variabilidade explicada pelas duas é de quase 95%, ou seja, explicam muito sobre os dados.

\begin{table}[H]
\centering
\caption{Inércia e Proporção de Variabilidade Explicada}
\label{inercia}
\begin{tabular}{rrrrr}
  \hline
 \bf{Componentes} & \bf{Valor singular} & \bf{Inércia Princ.} & \bf{Percentual} & \bf{Percentual acum.} \\ 
  \hline
  1 & 0,1023 & 0,0105 & 59,08 & 59,08 \\ 
  2 & 0,0797 & 0,0064 & 35,87 & 94,96 \\ 
  3 & 0,0299 & 0,0009 & 5,03 & 100,00 \\ 
   \hline
\end{tabular}
\end{table}

Vemos na Figura \ref{biplot3} o gráfico Bi-plot. Podemos dizer que o status A está mais relacionada com saúde mental debilitada que as demais, os status B e C estão mais relacionadas com presença fraca, o status D está mais relacionada à presença moderada e o status E está mais longe da saúde mental boa.


```{r,fig.cap="Bi-Plot das duas primeiras componentes.\\label{biplot3}", fig.height=4.5}

# Componentes
resultFCA <- plot(resultCA,xlab="Componente 1",ylab="Componente 2",
                  cex=1.4,cex.lab=1.2) #Biplot
#
#xtable(resultFCA$rows,digits=4)
#xtable(resultFCA$cols,digits=4)

```

\newpage

# Questão 4

## Introdução

O problema a ser resolvido diz respeito a características relativas à saúde de 768 mulheres indianas, portadoras de uma herança genética chamada prima. O banco de dados contém 768 observações (mulheres) e 9 variáveis (medidas). Como existem muitos dados faltantes, foram retiradas todas as observações que continham pelo menos um dado faltante. Com isso, o número de observações diminuiu para 392. O objetivo é criar uma regra de classificação de diabetes em função das outras variáveis. Para realizar a análise desse banco, foi utilizado o software estatístico R.

```{r}
data("PimaIndiansDiabetes2")
indi = PimaIndiansDiabetes2 %>% na.omit()
indiP = indi %>% filter(diabetes == "pos") %>% dplyr::select(-c(diabetes,pedigree))
indiN = indi %>% filter(diabetes == "neg") %>% dplyr::select(-c(diabetes,pedigree))
```

## Análise descritiva

A Tabela \ref{med_res4} contém as medidas resumo das portadoras da herança genética "prima". Podemos notar que, com exceção de "Gravidez" e "Tríceps" para o caso de diabetes positiva, a maioria das variáveis não tem uma curtose ideal (próxima de 3) e o coeficiente de assimetria da maioria das variáveis também não foram ideais.

A Figura \ref{disp_pos} e \ref{disp_neg} contém, respectivamente, a matriz de gráfico de dispersões das pacientes com diabetes e sem diabetes. Podemos notar correlações consideráveis para os pares "Gravidez" e "Idade", "Massa" e "Tríceps" e "Insulina" e "Glicose" sendo que este último par só possui valores consideráveis para o grupo das pacientes sem diabetes. A Tabela \ref{corr4} contém a matriz de correlação das pacientes com e sem diabetes.

As Figuras \ref{box_pos}, \ref{hist_pos} e \ref{qq_pos} contém, respectivamente, os boxplots, os histogramas e os QQplots de cada variável das pacientes com diabetes. Além disso, as Figuras \ref{box_neg}, ref{hist_pos} e \ref{qq_neg} possuem, respectivamente, os boxplots, os histogramas e os QQplots de cada variável das pacientes sem diabetes. Podemos perceber, pelas figuras, a existência de pelo menos uma variável que não segue uma distribuição normal. Sendo assim, rejeita-se a normalidade multivariada.

```{r}
SumIP<- cbind(round(apply(indiP,2,mean),4),round(apply(indiP,2,var),4),
                round(apply(indiP,2,sd),4),
                round(100*apply(indiP,2,sd)/apply(indiP,2,mean),4),
                round(apply(indiP,2,min),4),round(apply(indiP,2,quantile,0.5),4),
                round(apply(indiP,2,max),4),
                round(apply(indiP,2,skewness),4),
                round(apply(indiP,2,kurtosis),4))
colnames(SumIP)<-c("Média","Var.","DP","CV(%)","Min.","Med.","Max.",
                     "CA","Cur.")
#xtable(SumIP)
#SumIP
```

\begin{table}[H]
\centering
\caption{Medidas resumo das variáveis dos pacientes com diabetes positivo e negativo}
\label{med_res4}
\begin{tabular}{rrrrrrrrrr}
  \hline
 & Média & Var. & DP & CV(\%) & Min. & Med. & Max. & CA & Cur. \\ 
  \hline
  \multicolumn{10}{||c||}{Positivo} \\
  \hline
Gravidez & 4,47 & 15,34 & 3,92 & 87,62 & 0,00 & 3,00 & 17,00 & 0,81 & 2,91 \\ 
  Glicose & 145,19 & 890,39 & 29,84 & 20,55 & 78,00 & 144,50 & 198,00 & -0,14 & 2,08 \\ 
  Pressão & 74,08 & 169,56 & 13,02 & 17,58 & 30,00 & 74,00 & 110,00 & -0,13 & 3,96 \\ 
  Tríceps & 32,96 & 92,98 & 9,64 & 29,25 & 7,00 & 33,00 & 63,00 & 0,10 & 3,01 \\ 
  Insulina & 206,85 & 17609,26 & 132,70 & 64,15 & 14,00 & 169,50 & 846,00 & 1,86 & 7,31 \\ 
  Massa & 35,78 & 45,36 & 6,73 & 18,82 & 22,90 & 34,60 & 67,10 & 1,36 & 6,78 \\ 
  Idade & 35,94 & 113,10 & 10,63 & 29,59 & 21,00 & 33,00 & 60,00 & 0,57 & 2,20 \\ 
  \hline
  \multicolumn{10}{||c||}{Negativo} \\
  \hline
  Gravidez & 2,72 & 6,85 & 2,62 & 96,20 & 0,00 & 2,00 & 13,00 & 1,49 & 5,23 \\ 
  Glicose & 111,43 & 607,23 & 24,64 & 22,11 & 56,00 & 107,50 & 197,00 & 0,72 & 3,51 \\ 
  Pressão & 68,97 & 141,44 & 11,89 & 17,24 & 24,00 & 70,00 & 106,00 & -0,16 & 3,68 \\ 
  Tríceps & 27,25 & 108,87 & 10,43 & 38,29 & 7,00 & 27,00 & 60,00 & 0,35 & 2,49 \\ 
  Insulina & 130,85 & 10532,13 & 102,63 & 78,43 & 15,00 & 105,00 & 744,00 & 2,50 & 11,81 \\ 
  Massa & 31,75 & 46,17 & 6,79 & 21,40 & 18,20 & 31,25 & 57,30 & 0,43 & 3,13 \\ 
  Idade & 28,35 & 80,80 & 8,99 & 31,71 & 21,00 & 25,00 & 81,00 & 2,20 & 9,13 \\ 
   \hline
\end{tabular}
\end{table}

```{r}
SumIN<- cbind(round(apply(indiN,2,mean),4),round(apply(indiN,2,var),4),
                round(apply(indiN,2,sd),4),
                round(100*apply(indiN,2,sd)/apply(indiN,2,mean),4),
                round(apply(indiN,2,min),4),round(apply(indiN,2,quantile,0.5),4),
                round(apply(indiN,2,max),4),
                round(apply(indiN,2,skewness),4),
                round(apply(indiN,2,kurtosis),4))
colnames(SumIN)<-c("Média","Var.","DP","CV(%)","Min.","Med.","Max.",
                     "CA","Cur.")
#xtable(SumIN)
#SumIN
```

```{r,fig.cap="Matriz de gráfico de dispersões dos pacientes com diabetes positivo.\\label{disp_pos}"}
plot(indiP,cex=1.5,cex.lab=1.5,pch=1)
```

```{r,fig.cap="Matriz de gráfico de dispersões dos pacientes com diabetes negativo.\\label{disp_neg}"}
plot(indiN,cex=1.5,cex.lab=1.5,pch=1)
```

```{r}
#xtable(cor(indiP))
#cor(indiP)
```

\begin{table}[H]
\centering
\caption{Matriz de correlações dos pacientes com diabetes positivo}
\label{corr4}
\begin{tabular}{rrrrrrrr}
  \hline
  \multicolumn{8}{||c||}{Positivo} \\
  \hline
 & Gravidez & Glicose & Pressão & Tríceps & Insulina & Massa & Idade \\ 
  \hline
Gravidez & 1,00 & 0,02 & 0,18 & -0,07 & -0,00 & -0,19 & 0,60 \\ 
  Glicose & 0,02 & 1,00 & 0,09 & 0,04 & 0,40 & -0,03 & 0,19 \\ 
  Pressão & 0,18 & 0,09 & 1,00 & 0,16 & -0,07 & 0,19 & 0,27 \\ 
  Tríceps & -0,07 & 0,04 & 0,16 & 1,00 & 0,05 & 0,59 & -0,12 \\ 
  Insulina & -0,00 & 0,40 & -0,07 & 0,05 & 1,00 & -0,02 & 0,22 \\ 
  Massa & -0,19 & -0,03 & 0,19 & 0,59 & -0,02 & 1,00 & -0,18 \\ 
  Idade & 0,60 & 0,19 & 0,27 & -0,12 & 0,22 & -0,18 & 1,00 \\ 
   \hline
  \multicolumn{8}{||c||}{Negativo} \\
  \hline
  & Gravidez & Glicose & Pressão & Tríceps & Insulina & Massa & Idade \\
  \hline
  Gravidez & 1,00 & 0,14 & 0,17 & 0,10 & 0,01 & -0,04 & 0,70 \\ 
  Glicose & 0,14 & 1,00 & 0,16 & 0,11 & 0,62 & 0,15 & 0,21 \\ 
  Pressão & 0,17 & 0,16 & 1,00 & 0,21 & 0,12 & 0,31 & 0,24 \\ 
  Tríceps & 0,10 & 0,11 & 0,21 & 1,00 & 0,15 & 0,66 & 0,20 \\ 
  insulin & 0,01 & 0,62 & 0,12 & 0,15 & 1,00 & 0,27 & 0,05 \\ 
  Massa & -0,04 & 0,15 & 0,31 & 0,66 & 0,27 & 1,00 & 0,06 \\ 
  Idade & 0,70 & 0,21 & 0,24 & 0,20 & 0,05 & 0,06 & 1,00 \\  
   \hline
\end{tabular}
\end{table}


```{r,fig.cap="Boxplots das variáveis dos pacientes com diabetes positivo.\\label{box_pos}"}
par(mfrow=c(2,4))
boxplot(indiP[,1],cex=1.2,cex.lab=1.2,main="Gravidez (P)")
boxplot(indiP[,2],cex=1.2,cex.lab=1.2,main="Glicose (P)")
boxplot(indiP[,3],cex=1.2,cex.lab=1.2,main="Pressão (P)")
boxplot(indiP[,4],cex=1.2,cex.lab=1.2,main="Tríceps (P)")
boxplot(indiP[,5],cex=1.2,cex.lab=1.2,main="Insulinaa (P)")
boxplot(indiP[,6],cex=1.2,cex.lab=1.2,main="IMC (P)")
boxplot(indiP[,7],cex=1.2,cex.lab=1.2,main="idade (P)")
```

```{r,fig.cap="Boxplots das variáveis dos pacientes com diabetes negativo.\\label{box_neg}"}
par(mfrow = c(2,4))
boxplot(indiN[,1],cex=1.2,cex.lab=1.2,main="Gravidez (N)")
boxplot(indiN[,2],cex=1.2,cex.lab=1.2,main="Glicose (N)")
boxplot(indiN[,3],cex=1.2,cex.lab=1.2,main="Pressão (N)")
boxplot(indiN[,4],cex=1.2,cex.lab=1.2,main="Tríceps (N)")
boxplot(indiN[,5],cex=1.2,cex.lab=1.2,main="Insulinaa (N)")
boxplot(indiN[,6],cex=1.2,cex.lab=1.2,main="IMC (N)")
boxplot(indiN[,7],cex=1.2,cex.lab=1.2,main="Idade (N)")
```

```{r,fig.cap="Histogramas das variáveis dos pacientes com diabetes positivo.\\label{hist_pos}"}
par(mfrow=c(2,4))
hist(indiP[,1],probability=TRUE,main="Gravidez (P)",xlab="",ylab="")
hist(indiP[,2],probability=TRUE,main="Glicose (P)",xlab="",ylab="")
hist(indiP[,3],probability=TRUE,main="Pressão (P)",xlab="",ylab="")
hist(indiP[,4],probability=TRUE,main="Tríceps (P)",xlab="",ylab="")
hist(indiP[,5],probability=TRUE,main="Insulinaa (P)",xlab="",ylab="")
hist(indiP[,6],probability=TRUE,main="IMC (P)",xlab="",ylab="")
hist(indiP[,7],probability=TRUE,main="Idade (P)",xlab="",ylab="")
```

```{r,fig.cap="Histogramas das variáveis dos pacientes com diabetes negativo.\\label{hist_neg}"}
par(mfrow=c(2,4))
hist(indiN[,1],probability=TRUE,main="Gravidez (N)",xlab="",ylab="")
hist(indiN[,2],probability=TRUE,main="Glicose (N)",xlab="",ylab="")
hist(indiN[,3],probability=TRUE,main="Pressão (N)",xlab="",ylab="")
hist(indiN[,4],probability=TRUE,main="Tríceps (N)",xlab="",ylab="")
hist(indiN[,5],probability=TRUE,main="Insulinaa (N)",xlab="",ylab="")
hist(indiN[,6],probability=TRUE,main="IMC (N)",xlab="",ylab="")
hist(indiN[,7],probability=TRUE,main="Idade (N)",xlab="",ylab="")
```

```{r,fig.cap="QQplots das variáveis dos pacientes com diabetes positivo.\\label{qq_pos}"}
par(mfrow=c(2,4))
qqPlot(scale(indiP[,1]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Gravidez (P)",cex=1.2) %>% invisible()
qqPlot(scale(indiP[,2]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Glicose (P)",cex=1.2) %>% invisible()
qqPlot(scale(indiP[,3]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Pressão (P)",cex=1.2) %>% invisible()
qqPlot(scale(indiP[,4]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Tríceps (P)",cex=1.2) %>% invisible()
qqPlot(scale(indiP[,5]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Insulinaa (P)",cex=1.2) %>% invisible()
qqPlot(scale(indiP[,6]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="IMC (P)",cex=1.2) %>% invisible()
qqPlot(scale(indiP[,7]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Idade (P)",cex=1.2) %>% invisible()
```

```{r,fig.cap="QQplots das variáveis dos pacientes com diabetes positivo.\\label{qq_neg}"}
par(mfrow=c(2,4))
qqPlot(scale(indiP[,1]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Gravidez (N)",cex=1.2) %>% invisible()
qqPlot(scale(indiP[,2]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Glicose (N)",cex=1.2) %>% invisible()
qqPlot(scale(indiP[,3]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Pressão (P)",cex=1.2) %>% invisible()
qqPlot(scale(indiP[,4]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Tríceps (N)",cex=1.2) %>% invisible()
qqPlot(scale(indiP[,5]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Insulinaa (N)",cex=1.2) %>% invisible()
qqPlot(scale(indiP[,6]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="IMC (N)",cex=1.2) %>% invisible()
qqPlot(scale(indiP[,7]),dist="norm",mean=0,sd=1,col.lines=1,grid="FALSE",xlab="quantil da N(0,1)",ylab="Idade (N)",cex=1.2) %>% invisible()
```

## Análise Inferencial

A análise discriminante para duas populações foi a metodologia escolhida para a classificação entre diabetes positiva e diabetes negativa. Sabe-se que existem suposições para o modelo. Dois metódos equivalentes, um que supõe normalidade multivariada e homocedasticidade entre as duas populações e outro que somente supõe homocedasticidade entre as duas populações (Método de Fisher).

Um teste de homocedasticidade, com nível de significância de 0,05, retornou um p-valor de, aproximadamente, 0,0228. Portanto, rejeitamos a hipótese de homocedasticidade entre as duas populações. 

Como nenhum dos dois modelos tem suas suposições respeitadas, não há diferença entre eles nesse problema. 

A probabilidade à priori foi definida como a proporção de observações de cada categoria do banco de dados (cerca de 67\% sem diabetes e 33\% com diabetes). Mais informações sobre a metodologia podem ser encontradas em Azevedo (2020).

O banco de dados foi separado em treino e teste. No conjunto de treino, a análise discriminante foi aplicada. A Tabela \ref{confusao} contém a matriz de confusão da análise discriminante no conjunto de teste. Com isso, a taxa de erro aparente foi de, aproximadamente, 31\% e a taxa de erro ótimo foi de, aproximadamente, 39\%.

```{r}
set.seed(198105)
indid = indi %>% dplyr::select(-pedigree) %>% arrange(diabetes)
#treinoP <- sort(sample(1:130,104,replace=FALSE)) #80% das observações para treino
#treinoN <- sort(sample(131:392,210,replace=FALSE)) #80% das observações para treino
treinoP <- sort(sample(1:130,65,replace=FALSE)) #50% das observações para treino
treinoN <- sort(sample(131:392,131,replace=FALSE)) #50% das observações para treino
treino <- c(treinoP,treinoN)
```

```{r}
atrein <- indid[treino,]
```

```{r}
m.X <- rbind(indid[1:130,1:7],indid[131:392,1:7])
Sp = c(rep("P",130),rep("N",262))
m.Indi <- data.frame(m.X,Sp)
#table(m.Indi$Sp[treino])
#result.ad <- lda(Sp~., m.Iris, prior = c(1,1)/2,subset = treino)
result.ad <- lda(Sp~., m.Indi[,1:7], prior = c(2,1)/3,subset = treino)
#result.ad
```

```{r}
pred <- predict(result.ad, m.Indi[-treino, ])$class
```

```{r}
y <-predict(result.ad, m.Indi[-treino, ])$x
```

```{r}
data.teste <- m.Indi[-treino,8]
```



```{r}
tc <- table(data.teste,pred)
#xtable(tc)
```
\begin{table}[ht]
\centering
\caption{Matriz de confusão do teste}
\label{confusao}
\begin{tabular}{rrr}
  \hline
 & Negativo & Positivo \\ 
  \hline
  Negativo & 123 &   8 \\ 
  Positivo &  53 &  12 \\ 
   \hline
\end{tabular}
\end{table}



```{r}
TEA <- (tc[1,2]+tc[2,1])/sum(tc)
#100*TEA
```

```{r}
m.dados.iris <- m.Indi[treino,]
#  Dados.1 <- m.dados.iris[m.dados.iris[,5]=="VE",][,]
#  Dados.2 <- m.dados.iris[m.dados.iris[,5]=="VI",][,]
Dados.1 <- (m.dados.iris[m.dados.iris[,8]=="N",][,1:7])
Dados.2 <- (m.dados.iris[m.dados.iris[,8]=="P",][,1:7])
v.mean1 <- cbind(c(result.ad$means[1,]))
v.mean2 <- cbind(c(result.ad$means[2,]))
S21 <- cov(Dados.1[,1:7])
S22 <- cov(Dados.2[,1:7])
Sp <- ((nrow(Dados.1)-1)*S21 +  ((nrow(Dados.2)-1)*S22))/(nrow(Dados.1) + nrow(Dados.2) - 2)
q.classifi <- 0.5*t(v.mean1-v.mean2)%*%solve(Sp)%*%(v.mean1+v.mean2)
delta2 <-  t(v.mean1-v.mean2)%*%solve(Sp)%*%(v.mean1 - v.mean2)
#
TOE <- pnorm(-sqrt(delta2)/2)
#100*TOE
#xtable(cbind(v.mean1,v.mean2))
#xtable(S21)
#xtable(S22)
```


```{r}
m = 0.5*(t(v.mean1-v.mean2))%*%solve(Sp)%*%((v.mean1-v.mean2))
  
# Função linear discriminante
  
Y <- t(v.mean1-v.mean2)%*%solve(Sp)%*%t(as.matrix(m.Indi[-treino,1:7]))
m = 0.5*(t(v.mean1-v.mean2))%*%solve(Sp)%*%((v.mean1+v.mean2))
  
# Comparação entre os coeficientes Coeficientes
#cbind(t(t(v.mean1-v.mean2)%*%solve(Sp)),result.ad$scaling)
#(t(t(v.mean1-v.mean2)%*%solve(Sp)))/result.ad$scaling

# Análise da função discriminante para a amostra teste
grupo <- as.factor(c(rep("N",131), rep("P",65)))
# Medidas resumo
datadados<-data.frame(y,grupo)
colnames(datadados)<-c("y","dados")
medados<-ddply(datadados,.(grupo),summarise,media=mean(y),dp=sqrt(var(y)),vari=var(y),minimo=min(y),mediana=quantile(y,0.5),maximo=max(y),n=length(y))
colnames(medados)<-c("Grupo","Média","DP","Var.","Mínimo","Mediana","Máximo","n")
#xtable(medados)
```

A Tabela \ref{discmed} contém as medidas resumo das funções discriminantes. O grupo positivo tem a média negativa para a função discriminante, enquanto que o grupo positivo tem a média positiva. Nas Figuras \ref{boxdisc} e \ref{dendisc} temos os boxplot das funções discriminantes e as densidades estimadas das funções discriminantes, respectivamente. Através delas podemos notar que grande parte dos valores das funções discriminantes estão sobrepostos. Com isso, a classificação se torna confusa, obtendo a taxa de erro aparente e taxa de erro ótimo altos.

\begin{table}[ht]
\centering
\caption{Medidas resumo das funções discriminantes}
\label{discmed}
\begin{tabular}{rlrrrrrrr}
  \hline
 & Grupo & Média & DP & Var. & Mínimo & Mediana & Máximo & n \\ 
  \hline
1 & Negativo & 0,39 & 0,93 & 0,87 & -3,32 & 0,57 & 2,06 & 131 \\ 
  2 & Positivo & -0,78 & 0,92 & 0,85 & -3,67 & -0,71 & 0,70 &  65 \\ 
   \hline
\end{tabular}
\end{table}

```{r,fig.cap="Boxplots das funções discriminantes.\\label{boxdisc}"}
# boxplot
grupo <- as.character(grupo)
grupo[grupo == "N"] <- "Negativo"
grupo[grupo == "P"] <- "Positivo"
grupo <- factor(grupo, levels = c("Negativo", "Positivo"))
par(mfrow=c(1,1))
boxplot(y~grupo,cex=1.2,cex.lab=1.2)
#
```


```{r,fig.cap="Densidades estimadas das funções discriminantes.\\label{dendisc}"}
grupo <- as.character(grupo)
grupo[grupo == "Negativo"] <- "N"
grupo[grupo == "Positivo"] <- "P"
grupo <- factor(grupo, levels = c("N", "P"))

# densidades
plot(density(y[grupo=="P",1]),lwd=2,xlim=c(min(y[,1])-1,max(y[,1])+3),xlab="função discriminante",ylab="densidade",cex=1.2,cex.lab=1.2,cex.main=1.2,main="",ylim=c(0,0.9))
lines(density(y[grupo=="N",1]),col=2,lwd=2)
legend(2,0.6,lwd=c(2,2),col=c(1,2),legend=c("Positivo","Negativo"),bty="n",cex=1.2)

#hist(y[grupo=="P"],probability=TRUE,cex=1.2,cex.lab=1.2)
#hist(y[grupo=="N"],probability=TRUE,cex=1.2,cex.lab=1.2)
```

\subsection*{Referências}

\textit{Azevedo, C. L. N. (2020). Notas de aula sobre análise discriminante} <https://www.ime.unicamp.br/~cnaber/Material_AM_2S_2020.htm>.

## Apêndice

```{r}
#xtable(cov(indiP))
#cov(indiP)

#Box.teste.Igual.MCov(dplyr::select(dplyr::arrange(indi, diabetes), -diabetes), v.grupos = as.vector(cbind(as.numeric(factor(indi$diabetes)))), v.n = c(262,130), G = 2)
```

\begin{table}[H]
\centering
\caption{Matriz de covariâncias dos pacientes com diabetes positivo}
\label{cov4}
\begin{tabular}{rrrrrrrr}
  \hline
  \multicolumn{8}{||c||}{Positivo} \\
  \hline
 & Gravidez & Glicose & Pressão & Tríceps & Insulina & Massa & Idade \\ 
  \hline
Gravidez & 15,34 & 2,17 & 9,00 & -2,67 & -1,73 & -4,90 & 25,19 \\ 
  Glicose & 2,17 & 890,39 & 35,98 & 10,82 & 1576,11 & -5,35 & 60,11 \\ 
  Pressão & 9,00 & 35,98 & 169,56 & 19,72 & -126,61 & 17,02 & 37,49 \\ 
  Tríceps & -2,67 & 10,82 & 19,72 & 92,98 & 66,34 & 38,44 & -12,60 \\ 
  Insulina & -1,73 & 1576,11 & -126,61 & 66,34 & 17609,26 & -17,50 & 310,66 \\ 
  Massa & -4,90 & -5,35 & 17,02 & 38,44 & -17,50 & 45,36 & -12,63 \\ 
  Idade & 25,19 & 60,11 & 37,49 & -12,60 & 310,66 & -12,63 & 113,10 \\
  \hline
  \multicolumn{8}{||c||}{Negativo} \\
  \hline
  & Gravidez & Glicose & Pressão & Tríceps & Insulina & Massa & Idade \\
  \hline
  Gravidez & 6,85 & 8,72 & 5,41 & 2,71 & 1,80 & -0,78 & 16,48 \\ 
  Glicose & 8,72 & 607,23 & 46,15 & 27,16 & 1560,34 & 25,46 & 47,03 \\ 
  Pressão & 5,41 & 46,15 & 141,44 & 26,33 & 152,53 & 24,79 & 25,86 \\ 
  Tríceps & 2,71 & 27,16 & 26,33 & 108,87 & 163,90 & 46,90 & 18,76 \\ 
  Insulina & 1,80 & 1560,34 & 152,53 & 163,90 & 10532,13 & 190,04 & 48,66 \\ 
  Massa & -0,78 & 25,46 & 24,79 & 46,90 & 190,04 & 46,17 & 3,56 \\ 
  Idade & 16,48 & 47,03 & 25,86 & 18,76 & 48,66 & 3,56 & 80,80 \\
   \hline
\end{tabular}
\end{table}


